{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6c958ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().resolve().parent.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiments\n",
    "from experiments.run_sweep import run_sweep\n",
    "from experiments.run_experiment import TrainingConfig, EvaluateConfig\n",
    "from experiments.sweep_plots import plot_sweep_training, plot_sweep_evaluation\n",
    "from experiments.sweep_plots_helper import taxi_training_plot_specs, taxi_evaluation_plot_specs\n",
    "from experiments.notebook_helpers import generate_alpha_pairs, asymmetric_alphas\n",
    "\n",
    "\n",
    "# environments\n",
    "from environments.taxi_v3 import TaxiV3Config, get_taxi_v3_env\n",
    "\n",
    "# SARSA confirmation bias agent\n",
    "from agents.sarsa_td0_confirmation_bias import (\n",
    "    SarsaTD0ConfirmationBiasConfig,\n",
    "    SarsaTD0ConfirmationBiasAgent,\n",
    ")\n",
    "\n",
    "# metrics for training\n",
    "from metrics.reward_mertrics import taxi_v3_reward_metrics_specs\n",
    "from metrics.frustration_metrics import frustration_metrics_specs\n",
    "\n",
    "# external libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a7d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_AGENT_CONFIG_CONF = dict(\n",
    "    alpha_conf=0.2,\n",
    "    alpha_disconf=0.2,\n",
    "    gamma=0.99,\n",
    "    epsilon=0.2,\n",
    "    reward_metrics=taxi_v3_reward_metrics_specs(),\n",
    "    td_error_metrics=frustration_metrics_specs(),\n",
    ")\n",
    "\n",
    "\n",
    "BASE_AGENT_CONFIG_POSITITY = dict(\n",
    "    alpha_positive=0.2,\n",
    "    alpha_negative=0.2,\n",
    "    gamma=0.99,\n",
    "    epsilon=0.2,\n",
    "    reward_metrics=taxi_v3_reward_metrics_specs(),\n",
    "    td_error_metrics=frustration_metrics_specs(),\n",
    ")\n",
    "\n",
    "NUM_TRAIN_EPISODES = 50000\n",
    "NUM_EVAL_EPISODES = 5000\n",
    "NUM_SEEDS = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eded1d62",
   "metadata": {},
   "source": [
    "## Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "774859a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = TaxiV3Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc60c7b",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ad17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agents\n",
    "# sarsa_td0 confirmation bias agent\n",
    "agent_factory = SarsaTD0ConfirmationBiasAgent\n",
    "sarsa_td0_config = SarsaTD0ConfirmationBiasConfig(**BASE_AGENT_CONFIG_CONF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0275606c",
   "metadata": {},
   "source": [
    "## Sweep configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train = TrainingConfig(\n",
    "    name=\"TaxiV3_sarsa_td0\",\n",
    "    num_train_episodes=NUM_TRAIN_EPISODES,\n",
    "    env_kwargs={\"config\": env_config},\n",
    "    agent_kwargs={\"config\": sarsa_td0_config},\n",
    ")\n",
    "\n",
    "base_eval = EvaluateConfig(\n",
    "    name=\"TaxiV3_sarsa_td0\",\n",
    "    num_eval_episodes=NUM_EVAL_EPISODES,  # use >0 if you want eval outputs\n",
    "    env_kwargs={\"config\": env_config},\n",
    "    evaluation_metrics=taxi_v3_reward_metrics_specs(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c3f8b",
   "metadata": {},
   "source": [
    "## Confirmation bias results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "174f657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different q_tables\n",
    "env = get_taxi_v3_env(env_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755bfd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create different initial q_tables for the Taxi sweep\n",
    "env = get_taxi_v3_env(env_config)\n",
    "num_states = env.observation_space.n\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "out_dir = Path(\"outputs/sweeps\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# q-table setup (same as FrozenLake version)\n",
    "q0 = np.zeros((num_states, num_actions), dtype=np.float64)\n",
    "q_tables = [(\"zeros\", q0)]\n",
    "\n",
    "# confirmation-bias alpha pairs\n",
    "confirmatory_pairs, balanced_pairs, disconfirmatory_pairs = generate_alpha_pairs(\n",
    "    balanced_lr=[0.2], num_pairs=5, step_size=0.025\n",
    ")\n",
    "\n",
    "# use all pair groups\n",
    "alpha_pairs = confirmatory_pairs + balanced_pairs + disconfirmatory_pairs\n",
    "seeds = list(range(NUM_SEEDS))\n",
    "\n",
    "all_results = []\n",
    "done_pairs = []\n",
    "\n",
    "for a_conf, a_disconf in alpha_pairs:\n",
    "    # safe file name for float values\n",
    "    pair_tag = f\"ac_{a_conf:.3f}_ad_{a_disconf:.3f}\".replace(\".\", \"p\")\n",
    "    out_file = out_dir / f\"taxi_conf_{pair_tag}.pkl\"\n",
    "\n",
    "    # resume behavior\n",
    "    if out_file.exists():\n",
    "        print(f\"Skipping pair=({a_conf}, {a_disconf}) (already exists): {out_file}\")\n",
    "        with out_file.open(\"rb\") as f:\n",
    "            pair_results = pickle.load(f)\n",
    "        all_results.extend(pair_results)\n",
    "        done_pairs.append((a_conf, a_disconf))\n",
    "        continue\n",
    "\n",
    "    sweep_one_pair = {\n",
    "        \"agent_kwargs\": [\n",
    "            {\n",
    "                \"alpha_conf\": a_conf,\n",
    "                \"alpha_disconf\": a_disconf,\n",
    "                \"seed\": seed,\n",
    "                \"initial_q_table\": q_table.copy(),\n",
    "                \"initial_q_table_label\": label,\n",
    "            }\n",
    "            for (label, q_table) in q_tables\n",
    "            for seed in seeds\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    print(f\"Running Taxi pair=({a_conf}, {a_disconf}) with {len(seeds)} seeds...\")\n",
    "    pair_results = run_sweep(\n",
    "        base_training=base_train,\n",
    "        base_evaluation=base_eval,\n",
    "        sweep=sweep_one_pair,\n",
    "        env_factory=get_taxi_v3_env,\n",
    "        agent_factory=agent_factory,\n",
    "    )\n",
    "\n",
    "    # save immediately\n",
    "    with out_file.open(\"wb\") as f:\n",
    "        pickle.dump(pair_results, f)\n",
    "\n",
    "    all_results.extend(pair_results)\n",
    "    done_pairs.append((a_conf, a_disconf))\n",
    "    print(f\"Saved pair=({a_conf}, {a_disconf}) -> {out_file}\")\n",
    "\n",
    "# optional combined file\n",
    "combined_file = out_dir / \"taxi_conf_all_pairs.pkl\"\n",
    "with combined_file.open(\"wb\") as f:\n",
    "    pickle.dump(all_results, f)\n",
    "\n",
    "print(f\"Done pairs: {len(done_pairs)} / {len(alpha_pairs)}\")\n",
    "print(f\"Total runs collected: {len(all_results)}\")\n",
    "# print(f\"Combined saved to: {combined_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539bc054",
   "metadata": {},
   "source": [
    "## Positivity bias results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c5e88625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARSA positivty bias agent\n",
    "from agents.sarsa_td0_positivity_bias import (\n",
    "    SarsaTD0PositivityBiasConfig,\n",
    "    SarsaTD0PositivityBiasAgent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde3c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agents\n",
    "# sarsa_td0 agent\n",
    "agent_factory = SarsaTD0PositivityBiasAgent\n",
    "sarsa_td0_config = SarsaTD0PositivityBiasConfig(**BASE_AGENT_CONFIG_POSITITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a983e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train = TrainingConfig(\n",
    "    name=\"TaxiV3_sarsa_td0\",\n",
    "    num_train_episodes=NUM_TRAIN_EPISODES,\n",
    "    env_kwargs={\"config\": env_config},\n",
    "    agent_kwargs={\"config\": sarsa_td0_config},\n",
    ")\n",
    "\n",
    "base_eval = EvaluateConfig(\n",
    "    name=\"TaxiV3_sarsa_td0\",\n",
    "    num_eval_episodes=NUM_TRAIN_EPISODES,\n",
    "    env_kwargs={\"config\": env_config},\n",
    "    evaluation_metrics=taxi_v3_reward_metrics_specs(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "97c4d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different q_tables\n",
    "env = get_taxi_v3_env(env_config)\n",
    "num_states = env.observation_space.n\n",
    "num_actions = env.action_space.n\n",
    "q0 = np.zeros((num_states, num_actions), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d59ac06c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "range expected at least 1 argument, got 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[155], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m a_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m      3\u001b[0m ratios \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.1\u001b[39m, \u001b[38;5;241m1.2\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m seeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m sweep \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      9\u001b[0m         {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     ],\n\u001b[1;32m     18\u001b[0m }\n",
      "\u001b[0;31mTypeError\u001b[0m: range expected at least 1 argument, got 0"
     ]
    }
   ],
   "source": [
    "# mean alpha_0 = 0.2\n",
    "a_0 = 0.2\n",
    "ratios = [0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "\n",
    "seeds = list(range())\n",
    "\n",
    "sweep = {\n",
    "    \"agent_kwargs\": [\n",
    "        {\n",
    "            **asymmetric_alphas(a_0, r),  # gives alpha_positive / alpha_negative\n",
    "            \"seed\": seed,\n",
    "            \"initial_q_table\": q0,\n",
    "            \"initial_q_table_label\": \"zeros\",\n",
    "        }\n",
    "        for r in ratios\n",
    "        for seed in seeds\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2593d175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Taxi ratio=0.5 with 15 seeds...\n",
      "Saved ratio=0.5 -> outputs/sweeps/taxi_pos_ratio_0.5.pkl\n",
      "Running Taxi ratio=0.75 with 15 seeds...\n",
      "Saved ratio=0.75 -> outputs/sweeps/taxi_pos_ratio_0.75.pkl\n",
      "Running Taxi ratio=1.0 with 15 seeds...\n",
      "Saved ratio=1.0 -> outputs/sweeps/taxi_pos_ratio_1.0.pkl\n",
      "Running Taxi ratio=1.5 with 15 seeds...\n",
      "Saved ratio=1.5 -> outputs/sweeps/taxi_pos_ratio_1.5.pkl\n",
      "Running Taxi ratio=2.0 with 15 seeds...\n",
      "Saved ratio=2.0 -> outputs/sweeps/taxi_pos_ratio_2.0.pkl\n",
      "Running Taxi ratio=4.0 with 15 seeds...\n",
      "Saved ratio=4.0 -> outputs/sweeps/taxi_pos_ratio_4.0.pkl\n",
      "Done ratios: [0.5, 0.75, 1.0, 1.5, 2.0, 4.0]\n",
      "Total runs collected: 90\n",
      "Combined saved to: outputs/sweeps/taxi_pos_all_ratios.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Taxi setup\n",
    "env = get_taxi_v3_env(env_config)\n",
    "num_states = env.observation_space.n\n",
    "num_actions = env.action_space.n\n",
    "q0 = np.zeros((num_states, num_actions), dtype=np.float64)\n",
    "\n",
    "out_dir = Path(\"outputs/sweeps\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "a_0 = 0.2\n",
    "ratios = [4.0, 2.0, 1.5, 1.0, 0.75, 0.5]\n",
    "seeds = list(range(NUM_SEEDS))\n",
    "\n",
    "all_results = []\n",
    "done_ratios = []\n",
    "\n",
    "for r in ratios:\n",
    "    ratio_tag = str(r).replace(\".\", \"p\")\n",
    "    out_file = out_dir / f\"taxi_conf_ratio_{ratio_tag}.pkl\"\n",
    "\n",
    "    # Skip already completed ratio runs (resume behavior)\n",
    "    if out_file.exists():\n",
    "        print(f\"Skipping ratio={r} (already exists): {out_file}\")\n",
    "        with out_file.open(\"rb\") as f:\n",
    "            ratio_results = pickle.load(f)\n",
    "        all_results.extend(ratio_results)\n",
    "        done_ratios.append(r)\n",
    "        continue\n",
    "\n",
    "    sweep_one_ratio = {\n",
    "        \"agent_kwargs\": [\n",
    "            {\n",
    "                **asymmetric_alphas(\n",
    "                    a_0, r\n",
    "                ),  # expected to produce alpha_conf / alpha_disconf\n",
    "                \"seed\": seed,\n",
    "                \"initial_q_table\": q0.copy(),\n",
    "                \"initial_q_table_label\": \"zeros\",\n",
    "            }\n",
    "            for seed in seeds\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    print(f\"Running Taxi ratio={r} with {len(seeds)} seeds...\")\n",
    "    ratio_results = run_sweep(\n",
    "        base_training=base_train,\n",
    "        base_evaluation=base_eval,\n",
    "        sweep=sweep_one_ratio,\n",
    "        env_factory=get_taxi_v3_env,\n",
    "        agent_factory=agent_factory,\n",
    "    )\n",
    "\n",
    "    # Save immediately after each ratio\n",
    "    with out_file.open(\"wb\") as f:\n",
    "        pickle.dump(ratio_results, f)\n",
    "\n",
    "    all_results.extend(ratio_results)\n",
    "    done_ratios.append(r)\n",
    "    print(f\"Saved ratio={r} -> {out_file}\")\n",
    "\n",
    "# Optional combined file\n",
    "combined_file = out_dir / \"taxi_conf_all_ratios.pkl\"\n",
    "with combined_file.open(\"wb\") as f:\n",
    "    pickle.dump(all_results, f)\n",
    "\n",
    "print(f\"Done ratios: {done_ratios}\")\n",
    "print(f\"Total runs collected: {len(all_results)}\")\n",
    "print(f\"Combined saved to: {combined_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
