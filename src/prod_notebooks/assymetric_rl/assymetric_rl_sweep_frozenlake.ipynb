{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c958ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().resolve().parent.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiments\n",
    "from experiments.run_sweep import run_sweep\n",
    "from experiments.run_experiment import TrainingConfig, EvaluateConfig\n",
    "from experiments.sweep_plots import plot_sweep_training, plot_sweep_evaluation\n",
    "from experiments.sweep_plots_helper import frozenlake_training_plot_specs, frozenlake_evaluation_plot_specs\n",
    "from experiments.notebook_helpers import generate_alpha_pairs, asymmetric_alphas\n",
    "\n",
    "# environments\n",
    "from environments.fronzenlake import FrozenLakeConfig, get_frozenlake_env\n",
    "\n",
    "# SARSA confirmation bias agent\n",
    "from agents.sarsa_td0_confirmation_bias import (\n",
    "    SarsaTD0ConfirmationBiasConfig,\n",
    "    SarsaTD0ConfirmationBiasAgent,\n",
    ")\n",
    "\n",
    "# metrics for training\n",
    "from metrics.reward_mertrics import frozenlake_reward_metrics_specs\n",
    "from metrics.frustration_metrics import frustration_metrics_specs\n",
    "\n",
    "# external libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f76c1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_AGENT_CONFIG_CONF = dict(\n",
    "    alpha_conf=0.2,\n",
    "    alpha_disconf=0.2,\n",
    "    gamma=0.99,\n",
    "    epsilon=0.2,\n",
    "    reward_metrics=frozenlake_reward_metrics_specs(),\n",
    "    td_error_metrics=frustration_metrics_specs(),\n",
    ")\n",
    "\n",
    "\n",
    "BASE_AGENT_CONFIG_POSITITY = dict(\n",
    "    alpha_positive=0.2,\n",
    "    alpha_negative=0.2,\n",
    "    gamma=0.99,\n",
    "    epsilon=0.2,\n",
    "    reward_metrics=frozenlake_reward_metrics_specs(),\n",
    "    td_error_metrics=frustration_metrics_specs(),\n",
    ")\n",
    "\n",
    "NUM_TRAIN_EPISODES = 35000\n",
    "NUM_EVAL_EPISODES = 5000\n",
    "NUM_SEEDS = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eded1d62",
   "metadata": {},
   "source": [
    "## Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774859a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic environment\n",
    "env_config = FrozenLakeConfig(is_slippery=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc60c7b",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ad17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agents\n",
    "# sarsa_td0 confirmation bias agent\n",
    "agent_factory = SarsaTD0ConfirmationBiasAgent\n",
    "sarsa_td0_config = SarsaTD0ConfirmationBiasConfig(**BASE_AGENT_CONFIG_CONF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0275606c",
   "metadata": {},
   "source": [
    "## Sweep configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train = TrainingConfig(\n",
    "    name=\"FrozenLake_sarsa_td0\",\n",
    "    num_train_episodes=NUM_TRAIN_EPISODES,\n",
    "    env_kwargs={\"config\": env_config},\n",
    "    agent_kwargs={\"config\": sarsa_td0_config},\n",
    ")\n",
    "\n",
    "base_eval = EvaluateConfig(\n",
    "    name=\"FrozenLake_sarsa_td0\",\n",
    "    num_eval_episodes=NUM_EVAL_EPISODES,  # use >0 if you want eval outputs\n",
    "    env_kwargs={\"config\": env_config},\n",
    "    evaluation_metrics=frozenlake_reward_metrics_specs(),\n",
    "    td_error_metrics=frustration_metrics_specs(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c3f8b",
   "metadata": {},
   "source": [
    "## Confirmation bias results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "174f657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different q_tables\n",
    "env = get_frozenlake_env(env_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c81130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create different initial q_tables for the sweep\n",
    "env = get_frozenlake_env(env_config)\n",
    "num_states = env.observation_space.n\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "out_dir = Path(\"outputs/sweeps\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# q-table setup\n",
    "q0 = np.zeros((num_states, num_actions), dtype=np.float64)\n",
    "q_tables = [(\"zeros\", q0)]\n",
    "\n",
    "# confirmation-bias alpha pairs\n",
    "confirmatory_pairs, balanced_pairs, disconfirmatory_pairs = generate_alpha_pairs(\n",
    "    balanced_lr=[0.2], num_pairs=5, step_size=0.025\n",
    ")\n",
    "\n",
    "# use all pair groups\n",
    "alpha_pairs = confirmatory_pairs + balanced_pairs + disconfirmatory_pairs\n",
    "seeds = list(range(NUM_SEEDS))\n",
    "\n",
    "all_results = []\n",
    "done_pairs = []\n",
    "\n",
    "for a_conf, a_disconf in alpha_pairs:\n",
    "    # safe file name for float values\n",
    "    pair_tag = f\"ac_{a_conf:.3f}_ad_{a_disconf:.3f}\".replace(\".\", \"p\")\n",
    "    out_file = out_dir / f\"frozenlake_conf_slippery_{pair_tag}.pkl\"\n",
    "\n",
    "    # resume behavior\n",
    "    if out_file.exists():\n",
    "        print(f\"Skipping pair=({a_conf}, {a_disconf}) (already exists): {out_file}\")\n",
    "        with out_file.open(\"rb\") as f:\n",
    "            pair_results = pickle.load(f)\n",
    "        all_results.extend(pair_results)\n",
    "        done_pairs.append((a_conf, a_disconf))\n",
    "        continue\n",
    "\n",
    "    sweep_one_pair = {\n",
    "        \"agent_kwargs\": [\n",
    "            {\n",
    "                \"alpha_conf\": a_conf,\n",
    "                \"alpha_disconf\": a_disconf,\n",
    "                \"seed\": seed,\n",
    "                \"initial_q_table\": q_table,\n",
    "                \"initial_q_table_label\": label,\n",
    "            }\n",
    "            for (label, q_table) in q_tables\n",
    "            for seed in seeds\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    print(f\"Running FrozenLake pair=({a_conf}, {a_disconf}) with {len(seeds)} seeds...\")\n",
    "    pair_results = run_sweep(\n",
    "        base_training=base_train,\n",
    "        base_evaluation=base_eval,\n",
    "        sweep=sweep_one_pair,\n",
    "        env_factory=get_frozenlake_env,\n",
    "        agent_factory=agent_factory,\n",
    "    )\n",
    "\n",
    "    # save immediately\n",
    "    with out_file.open(\"wb\") as f:\n",
    "        pickle.dump(pair_results, f)\n",
    "\n",
    "    all_results.extend(pair_results)\n",
    "    done_pairs.append((a_conf, a_disconf))\n",
    "    print(f\"Saved pair=({a_conf}, {a_disconf}) -> {out_file}\")\n",
    "\n",
    "# optional combined file\n",
    "combined_file = out_dir / \"frozenlake_conf_slippery_all_pairs.pkl\"\n",
    "with combined_file.open(\"wb\") as f:\n",
    "    pickle.dump(all_results, f)\n",
    "\n",
    "print(f\"Done pairs: {len(done_pairs)} / {len(alpha_pairs)}\")\n",
    "print(f\"Total runs collected: {len(all_results)}\")\n",
    "# print(f\"Combined saved to: {combined_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539bc054",
   "metadata": {},
   "source": [
    "## Positivity bias results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e88625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARSA positivty bias agent\n",
    "from agents.sarsa_td0_positivity_bias import (\n",
    "    SarsaTD0PositivityBiasConfig,\n",
    "    SarsaTD0PositivityBiasAgent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde3c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agents\n",
    "# sarsa_td0 agent\n",
    "agent_factory = SarsaTD0PositivityBiasAgent\n",
    "sarsa_td0_config = SarsaTD0PositivityBiasConfig(**BASE_AGENT_CONFIG_POSITITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a983e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train = TrainingConfig(\n",
    "    name=\"FrozenLake_sarsa_td0\",\n",
    "    num_train_episodes=NUM_TRAIN_EPISODES,\n",
    "    env_kwargs={\"config\": env_config},\n",
    "    agent_kwargs={\"config\": sarsa_td0_config},\n",
    ")\n",
    "\n",
    "base_eval = EvaluateConfig(\n",
    "    name=\"FrozenLake_sarsa_td0\",\n",
    "    num_eval_episodes=NUM_EVAL_EPISODES,\n",
    "    env_kwargs={\"config\": env_config},\n",
    "    evaluation_metrics=frozenlake_reward_metrics_specs(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c4d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different q_tables\n",
    "env = get_frozenlake_env(env_config)\n",
    "num_states = env.observation_space.n\n",
    "num_actions = env.action_space.n\n",
    "q0 = np.zeros((num_states, num_actions), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59ac06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "out_dir = Path(\"outputs/sweeps\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "a_0 = 0.2\n",
    "ratios = [4.0, 2.0, 1.5, 1.0, 0.75, 0.5]\n",
    "seeds = list(range(NUM_SEEDS))\n",
    "\n",
    "all_results = []\n",
    "done_ratios = []\n",
    "\n",
    "for r in ratios:\n",
    "    out_file = out_dir / f\"frozenlake_pos_slippery_ratio_{r}.pkl\"\n",
    "\n",
    "    # Skip already completed ratio runs (resume behavior)\n",
    "    if out_file.exists():\n",
    "        print(f\"Skipping ratio={r} (already exists): {out_file}\")\n",
    "        with out_file.open(\"rb\") as f:\n",
    "            ratio_results = pickle.load(f)\n",
    "        all_results.extend(ratio_results)\n",
    "        done_ratios.append(r)\n",
    "        continue\n",
    "\n",
    "    sweep_one_ratio = {\n",
    "        \"agent_kwargs\": [\n",
    "            {\n",
    "                **asymmetric_alphas(a_0, r),\n",
    "                \"seed\": seed,\n",
    "                \"initial_q_table\": q0,\n",
    "                \"initial_q_table_label\": \"zeros\",\n",
    "            }\n",
    "            for seed in seeds\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    print(f\"Running FrozenLake ratio={r} with {len(seeds)} seeds...\")\n",
    "    ratio_results = run_sweep(\n",
    "        base_training=base_train,\n",
    "        base_evaluation=base_eval,\n",
    "        sweep=sweep_one_ratio,\n",
    "        env_factory=get_frozenlake_env,  # FrozenLake env factory\n",
    "        agent_factory=agent_factory,\n",
    "    )\n",
    "\n",
    "    # Save immediately after each ratio\n",
    "    with out_file.open(\"wb\") as f:\n",
    "        pickle.dump(ratio_results, f)\n",
    "\n",
    "    all_results.extend(ratio_results)\n",
    "    done_ratios.append(r)\n",
    "    print(f\"Saved ratio={r} -> {out_file}\")\n",
    "\n",
    "# Optional combined file\n",
    "combined_file = out_dir / \"frozenlake_pos_slippery_all_ratios.pkl\"\n",
    "with combined_file.open(\"wb\") as f:\n",
    "    pickle.dump(all_results, f)\n",
    "\n",
    "print(f\"Done ratios: {done_ratios}\")\n",
    "print(f\"Total runs collected: {len(all_results)}\")\n",
    "print(f\"Combined saved to: {combined_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
